{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import pandas as pd\n",
      "import matplotlib\n",
      "%matplotlib inline\n",
      "matplotlib.rcParams['figure.figsize'] = (8, 6) # set default figure size, 8in by 6in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Video W4 01: Non-linear Hypothesis\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=mcnvIWDnPns&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=44)\n",
      "\n",
      "We have already seen some linear regression and logistic classification problems that would not\n",
      "be easily modeled using only linear assumptions.  A couple of times in the companion videos, it was\n",
      "mentioned that the techniques we developed do actually extend easily to using non-linear hypothesis.\n",
      "For example, we could expand a given set of features to include all of the quadratic combinations\n",
      "(raise to the second power).\n",
      "This can work ok if we only have a few 10s to 100s of original features, though we might have to expand\n",
      "beyond quadratic and even look at third power, fourth power combinations, etc.  For quadratic \n",
      "features, as the video mentions, the number of inputs will grow with the square of the number of\n",
      "original features, so a problem with 100 original inputs, would require about $10,000 / 2$ \n",
      "quadratic combinations, and higher order powers grow even faster.  Thus for problems of more than\n",
      "100 or so original inputs, it quickly becomes infeasable to model and solve these problems using\n",
      "standard regression methods.\n",
      "\n",
      "So these next two weeks we will be looking at a different learning method, neural networks.  Neural\n",
      "networks are able to create models or solutions using non-linear combinations of features, without\n",
      "the problems we just saw with the combinotorial explosion of combinations of the features.\n",
      "\n",
      "# Video W4 02: Neurons and the Brain\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=Nx3HVwg2uGA&index=45&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW)\n",
      "\n",
      "# Video W4 03: Model Representation I\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=wnSol2JRZeY&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=46)\n",
      "\n",
      "Neural networks use a \"hypothesis\" or model for individual units of computation that is the same\n",
      "as we have already seen.\n",
      "\n",
      "<img src=\"files/figures/nn-model-logistic-unit.png\">\n",
      "\n",
      "What happens in a neural network is that the inputs $x_1, x_2, x_3$ are multiplied by what are known as\n",
      "weights $w_1, w_2, w_3$, which are associated with the input wires in the diagram.  The weights are\n",
      "the same as the $\\theta_1, \\theta_2, \\theta_3$ parameters we have been using in the previous lectures\n",
      "(but by convention they are usually referred to as weights rather than parameters in the\n",
      "context of neural networks).  Inputs and weight\n",
      "parameters are multiplied and then summed together.  Then the output of the neuarl network unit\n",
      "is passed through a non-linear function.  The most common output function to use is the logistic\n",
      "(sigmoid) function, the same as we used for logistic regression:\n",
      "\n",
      "$$\n",
      "h_\\theta(x) = \\frac{1}{1 + e^{-\\theta^Tx}}\n",
      "$$\n",
      "\n",
      "But what makes a neural network different from a logistic regression, is that we organize the\n",
      "computation of the hypothesis into many small regression/calculations, and we combine multiple of\n",
      "these using 2 or more layers of the network.\n",
      "\n",
      "# Video W4 04: Model Representation II\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=vuhueI_7324&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=47)\n",
      "\n",
      "# Video W4 05: Examples and Intuitions I\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=BhWlHvjEn3s&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=48)\n",
      "\n",
      "# Video W4 06: Examples and Intuitions II\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=QZqmNpEyiKI&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=49)\n",
      "\n",
      "# Video W4 07: Multiclass Classification\n",
      "\n",
      "[YouTube Video Link](https://www.youtube.com/watch?v=HzpptanxP6A&list=PLZ9qNFMHZ-A4rycgrgOYma6zxF4BZGGPW&index=50)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}