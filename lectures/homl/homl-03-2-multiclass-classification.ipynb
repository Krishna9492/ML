{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports usually needed\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries more specific to this lecture notebook\n",
    "import os.path\n",
    "import sys\n",
    "sys.path.append('../../src')\n",
    "from ml_python_class.config import DATA_DIR\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook wide settings to make plots more readable and visually better to understand\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "mpl.rc('figure', titlesize=18)\n",
    "mpl.rcParams['figure.figsize'] = (10.0, 8.0) # default figure size if not specified in plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. (Chapter 3) Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the MNIST data set for the second half of this lecture/notebook\n",
    "#from sklearn.datasets import fetch_openml\n",
    "#mnist = fetch_openml('mnist_784', version=1)\n",
    "\n",
    "# extract the full data and target labels\n",
    "#X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the MNIST data set for the second half of this lecture/notebook\n",
    "mnist = pd.read_csv('../../data/mnist_784.csv')\n",
    "mnist = mnist.to_numpy()\n",
    "\n",
    "X = mnist[:, 0:-1]\n",
    "y = mnist[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertes to an integer using 8 bits, but we only need 4 bits here\n",
    "y = y.astype(np.uint8) \n",
    "\n",
    "# perform our train/test split of the data\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Multiclass Classification\n",
    "\n",
    "Binary classification is common, many problems have a label of true/false, yes/no, ham/spam, etc.\n",
    "But when the categorical output you want to predict is non-binary, we need to train a \n",
    "multiclass classifier (also sometimes called a multinomial classifier).\n",
    "\n",
    "Some algorithms (random forest, naive bayes classifiers) can handle multiple classes directly.\n",
    "Other algorithms (such as SVM or logistic classifiers) are strictly binary classifiers. However, \n",
    "you can always train multiple binary classifiers, one for each class/not-class (like 5s/not-5s) and \n",
    "then combine the results of the multiple binary classifiers to form a multiclass classifier.  \n",
    "\n",
    "For example, one strategy using MNIST as an example, would be to train a binary classifier for \n",
    "each digit.  If the classifier provides decision score, you can select the one whose decision\n",
    "score was highest as the multiclass output.  This is called a one-versus-all (OvA) stragey.\n",
    "\n",
    "More complicated, you can build a classifier for every pair, e.g. 0s vs. 1s, 0s vs. 2s...\n",
    "8s vs. 9s.  This is called one-versus-one (OvO) strategy.  If there are $N$ classes you need to train\n",
    "$N \\times (N -1) /2$ classifiers.  For MNIST this means a total of 45 classifiers are needed.  When \n",
    "you want to classify an image, you run it through all 45 classifiers, and see which classifier won\n",
    "the most duels. This becomes your multiclass classification output.\n",
    "\n",
    "The first strategy OvA scales linearly in size $\\mathcal{O}(N)$ of the number of classes, while OvA is\n",
    "$\\mathcal{O}(N^2)$, which can be a factor.  But OvO only uses a small portion of the dataset (when\n",
    "N is large) for each paired classifier.  When the algorithm scales poorly with the size of the \n",
    "training set, OvO might be preferred (such as SVMs).  But for most multiclass classification,\n",
    "OvA is preferred.\n",
    "\n",
    "\n",
    "`sklearn` mostly will do the details for you to build a multiclass classifier for those algorithms that \n",
    "are strictly binary in nature.  It will detect when you try and use a binary classification\n",
    "algorithm for a multiclass classification task and automatically set up and train OvA (except \n",
    "for SVM classifiers which use OvO).\n",
    "\n",
    "Lets try training a multiclass classifier on all 10 digit categories using the `SGDClassifier`\n",
    "again.  SGD is inherently binary, so `sklearn` sets up OvA and trains 10 classifiers for you,\n",
    "and combines the score/results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDClassifier(random_state=42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_num = 0\n",
    "some_digit = X[sample_num]\n",
    "\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked, though it will sometimes get the prediction wrong for the first digit (recall digit \n",
    "0 is a 5).  \n",
    "\n",
    "The above cell trains an `SGDClassifier` on the training set using the full multiclass set of y_train \n",
    "labels for supervised training.  Under the hood, `sklearn` actually trained 10 binary classifiers, \n",
    "got their decision scores for the image, and selected the class with the highest scores.\n",
    "\n",
    "We can see the raw decision scores for the 10 classifiers that were created using the \n",
    "`decision_function()` method.  Instead of returning a single socre, it returns 10 scores, one per \n",
    "each of the 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-31893.03095419, -34419.69069632,  -9530.63950739,\n",
       "          1823.73154031, -22320.14822878,  -1385.80478895,\n",
       "        -26188.91070951, -16147.51323997,  -4604.35491274,\n",
       "        -12050.767298  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest score should correspond to the class we got back from predict.  We can use argmax to \n",
    "get the index of the highest score, and convert that to the corresponding class (which is what\n",
    "`sklearn` is doing to get a final prediction from the 10 classifier score outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf.classes_[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to, we can explictly force OvO instead of OvA.  `sklearn` supports wrapper \n",
    "estimators named `OneVsOneClassifier` and `OneVsRestClassifier`.  These take a \n",
    "binary classifier as their meta-parameter, and sets up the appropriate multiclass\n",
    "configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "\n",
    "ovo_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice as discussed there are 45 individual OvO estimators created for this multiclass classifier\n",
    "len(ovo_clf.estimators_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training other multiclass classifires is just as easy.  We can train a `RandomForestClassifier`.\n",
    "The `RandomForestClassifier` can be used directly for multiclass classification, so `sklearn` \n",
    "did not have to run OvA or OvO here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5], dtype=uint8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)\n",
    "\n",
    "forest_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the list of probibilities that the classifier assigned to each instance of \n",
    "this class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.01, 0.08, 0.  , 0.9 , 0.  , 0.  , 0.  , 0.01]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.predict_proba([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the classifier here is fairly confident about its prediciton, it estimates a 90%\n",
    "probability that the image represents a 5.  It also thinks if might be a 3 with 8% change, and 2 and 9\n",
    "both have a small estimate of being the correct class as well.\n",
    "\n",
    "Now of course you want to evaluate these classifiers.  As usual we will use cross validation, \n",
    "though the confusion matrix is now going to be a 10x10 matrix when we evaluate.\n",
    "\n",
    "Lets evaluate the `SGDClassifiers` basic accuracy using `cross_val_score()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wheras before a basic score of 90% could be achieved by always guessing not-5, here something \n",
    "that always guesses the same thing, or a random guesser, will achieve a score of only 10%.  \n",
    "So an average accuracy of 85% or so is not too shabby here.  But we can do better (best known \n",
    "algorithms achieve over 99.9% cross validation accuracy on MNIST).\n",
    "\n",
    "We did not scale the inputs before training here, would that make a difference?  The\n",
    "range of values for the pixel image attributes are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"range minimum: \", X_train.min())\n",
    "print(\"range maximum: \", X_train.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value range from 0 to 255 (not 0 to 1 as I may have said before).  Scaling the inputs \n",
    "can get a slight increase for the SGD classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Error Analysis\n",
    "\n",
    "To improve our multiclass classifiers we might want to start with the confusion matrix again.  This \n",
    "could help us begin to analyze the types of errors and mistakes the classifier makes.  For example, \n",
    "is any class particularly difficult for the classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix is a lot of numbers, though you can see as you would expect most of the results are\n",
    "on correct classifications along the main diagonal.  Recall that rows are the true label here (with row \n",
    "0 for class 0 starting at the top, down to 9), and columns are the prediction made by the \n",
    "classifier. \n",
    "\n",
    "When working with more than a binary confusion matrix, it is often good visualize \n",
    "the numbers to better find patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.jet)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix looks fairly good, the 5's look slightly colder (meaning they are not \n",
    "getting classified correctly as much as other digits as we might expect).  \n",
    "\n",
    "But we really want to focus on the errors and find patterns if any there.  If we divide each \n",
    "row by the number of images in that class we can compare error rates instead of absolut number \n",
    "of errors.  Lets do that and replot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sum of each row, which is the number of instances of each class\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "\n",
    "# vectorized division will divide each value by the total values in the class, resulting in\n",
    "# a number between 0.0 and 1.0.  The diagnol will be the correct classification rate, and the \n",
    "# off diagnol elements will be the error rates for a particular combination of digits\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "norm_conf_mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the correct classifications diagnol with 0's, we want to only visualize the errors\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "\n",
    "# show the confusion matrix like before, but now with error rates and correct prediction rates removed\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.jet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These manipulations help the error pattern stand out much more clearly.  Recall that columns \n",
    "are the prediction.  Lots of things are being misclassified as an 8.  However the row for class 8 does\n",
    "not particularly stand out, meaning that actual 8's in general get properly classified. \n",
    "\n",
    "Another not quite so noticable pattern is that 2,5 and 5,2 are relatively hotter.  So 2's and 5's\n",
    "are being confused, which is certainly understandable.\n",
    "\n",
    "Notice that the confusion matrix is not necessarily symmetrical.  You might have thought that\n",
    "2,7 and 7,2 would have the same value.  But actual 2 being misclassified as a 7 can and will have \n",
    "a different count from actual 7 being misclassified as 2. \n",
    "\n",
    "Analyzing the confusion matrix can often give insights on ways to improve your classifier.  We should \n",
    "certainly concentrate on 8's here.\n",
    "\n",
    "Analyzing individual errors can also provide insights into what is going wrong with a ML\n",
    "classifier. For example, we might plot examples of 3's and 5s.\n",
    "\n",
    "This example from the textbook is ding things a bit by hand, but it pulls out examples of \n",
    "3s predicted correct, 3's misclassified as 5s, 5's misclassified as 3's and 5's classified\n",
    "correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_a, cl_b = 3, 5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The upper left and lower right are the correct 3 and correct 5 classifications. \n",
    "\n",
    "Some of the misclassifications are so bad it would be understandable for humans to \n",
    "make the misclassification.  The top row 2nd column of the misclassified 5s and the \n",
    "middle value of the misclassified 3's stand out.  Also the bottom row column 2 of the \n",
    "misclassified 5's looks like it could be an incorrect label in the dataset, this \n",
    "really looks like it was an actual 5 maybe?\n",
    "\n",
    "\n",
    "However most of the misclassifications seem like obvious mistakes, and it is hard to \n",
    "understand why the classifier made this misclassifications.  But the \n",
    "`SGDClassifier` is a simple linear model, so it is not surprising it has lots of obvious \n",
    "misclassifications.\n",
    "\n",
    "\n",
    "The main difference between 3s and 5s is the position of the small line that joins the\n",
    "top line to the bottom arc.  If the junction is shifted left, it seems more like a 5, \n",
    "and if shifted right, more like a 3.  This classifier might be sensitive to image shifting and rotation.\n",
    "So we might try to reduce 3/5 confusion by more heavily preprocessing the images to ensure \n",
    "they are well centered and not rotated.  This will probably help reduce other errors\n",
    "as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Multilabel Classification\n",
    "\n",
    "We have only discussed the case so far where each sample/instance has been assigned a single \n",
    "class.  But sometimes we might want a classifier that learns to output 2 or more labels.  \n",
    "If the output labels are all binary, we consider this a multilabel (binary) classificaiton \n",
    "system.\n",
    "\n",
    "We could just train separate classifiers.  But the inputs are the same, and thus what the system learns \n",
    "about associating an input with the multiple output labels might benefit if all of the classifiers \n",
    "are being trained with a common object/estimator.\n",
    "\n",
    "As a simple example, lets make a multilabel classification task.  We create 2 binary labels, whether \n",
    "the digit is large (a 7, 8 or 9) and whether or not the digit is odd (1, 3, 5, 7, 9).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "\n",
    "print(y_multilabel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multilabel training labels has 2 labels for each sample instance.\n",
    "\n",
    "As an example we introduce a `KNeighborsClassifier` classifer (which supports multilabel \n",
    "classification, but not all classifiers do).  We train it using the \n",
    "multiple targets array. \n",
    "\n",
    "Then we can make a prediction, notice two output labels are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)\n",
    "\n",
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier will probably get the multilabel correct here.  The digit here is a 5, so it is \n",
    "False that it is large, but True that it is odd.\n",
    "\n",
    "To evaluate such a classifier, you would probably evaluate each individual class performance, using\n",
    "ROC and/or recall/accuracy tradeoff scores.  To get a single metric, you could compute individual \n",
    "$F_1$ scores for each class and then compute the average $F_1$ score.  This code computes the average \n",
    "$F_1$ score across all labels.\n",
    "\n",
    "**Warning:** The following will take some significant time to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 Multioutput Classification\n",
    "\n",
    "Finally multilabel classification usually refers to multiple labels, binary category outputs.\n",
    "Some people call the most general case multioutput classification.  In the most general\n",
    "case, you can have multiple outputs, and the outputs can be multiclass instead of all \n",
    "binary classes.\n",
    "\n",
    "As a quick illustration, we build a system that removes noise from images.  It will take as input \n",
    "a noisy digit image, and it will (hopefully) output a clean digit image, represented as \n",
    "an array of pixel intensities.  So notice now instead of a single class, we want to output the \n",
    "same number of pixels as the input.  Hopefully the output pixels have removed noise from each corresponding \n",
    "input pixel.\n",
    "\n",
    "We will set up this task by creating a training set of noisy images from the original MNIST\n",
    "images.  We add noise to the pixel intensities using `numpy` `randint()` function.\n",
    "The target multioutput labels will be the original clean images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the noise pattern to be added to all images to create our new inputs\n",
    "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
    "\n",
    "# add the noise, a simple vectorized addition will suffice to add it to all of the samples in X_train\n",
    "X_train_noise = X_train + noise\n",
    "\n",
    "# do same for test data in case we need it\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
    "X_test_noise = X_test + noise\n",
    "\n",
    "y_train_noise = X_train\n",
    "y_test_noise = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the first noisy image\n",
    "digit_num = 0\n",
    "some_digit = X_train_noise[digit_num]\n",
    "plot_digit(some_digit)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its original clean version\n",
    "some_digit = y_train_noise[digit_num]\n",
    "plot_digit(some_digit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train the a knn classifier again on this multioutput multiclass task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train_noise, y_train_noise)\n",
    "\n",
    "digit_num = 0\n",
    "some_digit = X_train_noise[digit_num]\n",
    "clean_digit = knn_clf.predict([some_digit])\n",
    "\n",
    "plot_digit(clean_digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display version information of library versions used in this notebook\n",
    "from ml_python_class.custom_funcs import version_information\n",
    "version_information()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-datasci",
   "language": "python",
   "name": "python3-datasci"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
